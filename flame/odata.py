#! -*- coding: utf-8 -*-

# Description    Flame Odata class
##
# Authors:       Manuel Pastor (manuel.pastor@upf.edu)
##
# Copyright 2018 Manuel Pastor
##
# This file is part of Flame
##
# Flame is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation version 3.
##
# Flame is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
##
# You should have received a copy of the GNU General Public License
# along with Flame.  If not, see <http://www.gnu.org/licenses/>.

import os
import pickle
import tempfile
import numpy as np
from flame.util import utils, get_logger, supress_log
from datetime import datetime

from scipy.spatial.distance import MetricInfo

LOG = get_logger(__name__)

class Odata():
    """
    Transforms results into something readable?.

    TODO: Expand Class docstring
    """

    def __init__(self, parameters, conveyor, label=None):

        # previous results (eg. object names, mol descriptors) are retained
        self.param = parameters
        self.conveyor = conveyor
        self.format = self.param.getVal('output_format')
        self.label = self.conveyor.getVal("prediction_label")

        if self.label is None:
            self.label = 'temp'

    def _output_md(self):
        ''' dumps the molecular descriptors to a TSV file'''

        with open('output_md.tsv', 'w') as fo:

            # Make sure the keys 'var_nam', 'obj_nam', 'xmatrix' actualy exist
            # start writting MD
            if self.conveyor.isKey('var_nam'):
                # header: obj:name + var name

                header = 'name'
                var_nam = self.conveyor.getVal('var_nam')

                for nam in var_nam:
                    header += '\t'+nam
                fo.write(header+'\n')

            if self.conveyor.isKey('xmatrix') and self.conveyor.isKey('obj_nam'):
                # extract obj_name and xmatrix
                xmatrix = self.conveyor.getVal('xmatrix')
                obj_nam = self.conveyor.getVal('obj_nam')

                # iterate for objects
                shape = np.shape(xmatrix)

                if len(shape) > 1:  # 2D matrix (num_obj > 1)
                    for x in range(shape[0]):
                        line = obj_nam[x]
                        for y in range(shape[1]):
                            line += '\t'+str(xmatrix[x, y])
                        fo.write(line+'\n')

                else:             # 1D matrix (num_obj = 1)
                    line = obj_nam[0]
                    for y in range(shape[0]):
                        line += '\t'+str(xmatrix[y])
                    fo.write(line+'\n')

        LOG.info('Molecular descriptors dumped into output_md.tsv')

    def is_ensemble (self):
        if 'ghost' in self.format or 'profiling' in self.format:
            return True
        return False        

    def print_result (self, val):
        ''' Prints in the console the content of results given as an 
        argument (val) in a human-readable format 
        '''
        if len(val) < 3:
            LOG.info(f'       {val}')
        else:
            v3 = val[2]
            try:
                v3 = float(f'{v3:.4f}')
            except:
                pass
            LOG.info (f'       {val[0]} ( {val[1]} ) : {v3}')

    def run_learn(self):
        '''Process the results of learn,
        usually a report on the model quality
        '''
        # the ouput generated by the building are:
        # 
        # 1. model-results.pkl and model-meta.pkl
        # 2. console output
        # 3. molecular descriptors file in TSV format [optional]
        # 4. results file in TSV format [optional]
        # 

        ####
        # 1. model-results.pkl and model-meta.pkl
        ####
        model_path = self.param.getVal('model_path')

        results_pkl_path = os.path.join(model_path, 'model-results.pkl')
        LOG.debug(f'saving model results to: {results_pkl_path}')
        
        with open(results_pkl_path, 'wb') as handle:
            self.conveyor.save(handle)

        meta_pkl_path = os.path.join(model_path, 'model-meta.pkl')
        LOG.debug(f'saving model results to: {meta_pkl_path}')
        
        with open(meta_pkl_path, 'wb') as handle:
            pickle.dump (self.conveyor.getMeta('modelID'), handle)
            pickle.dump (self.conveyor.getErrorMessage(), handle)
            pickle.dump (self.conveyor.getWarningMessage(), handle)
            pickle.dump (self.conveyor.getVal('model_build_info'), handle)
            pickle.dump (self.conveyor.getVal('model_valid_info'), handle)
            pickle.dump (self.conveyor.getVal('model_type_info'), handle)

        ####
        # !  in case of error, print and return error
        ####
        if self.conveyor.getError():
            error_msg = self.conveyor.getErrorMessage()
            return False, error_msg

        ####
        # 2. console output
        ####
        if self.conveyor.isKey('model_build_info'):
            for val in self.conveyor.getVal('model_build_info'):
                self.print_result (val)

        if self.conveyor.isKey('model_valid_info'):
            for val in self.conveyor.getVal('model_valid_info'):
                self.print_result (val)

        ###
        # 3. molecular descriptors file in TSV format [optional]
        ###
        if self.param.getVal('output_md'):
            self._output_md()

        ###
        # 4. results file in TSV format [optional]
        ### 
        if 'TSV' in self.format:
            LOG.info('writting results to TSV file "output.tsv"')

            # label and smiles
            key_list = ['obj_nam']
            if self.conveyor.isKey('SMILES'):
                key_list.append('SMILES')

            # main result
            key_list += self.conveyor.getMain()

            # add all object type results
            for item in self.conveyor.objectKeys():
                if item not in key_list:
                    key_list.append(item)

            with open('output.tsv', 'w') as fo:
                header = ''
                for label in key_list:
                    header += label+'\t'
                fo.write(header+'\n')

                obj_num = int(self.conveyor.getVal('obj_num'))

                for i in range(obj_num):
                    line = ''
                    for key in key_list:

                        val_array = self.conveyor.getVal(key)

                        if val_array is None:
                            line += '-\t'
                            continue

                        if i >= len(val_array):
                            val = None
                        else:
                            val = val_array[i]

                        if val is None:
                            line += '-'
                        else:
                            if isinstance(val, float):
                                line += "%.4f" % val
                            else:
                                line += str(val)
                        line += '\t'
                    fo.write(line+'\n')

        return True, 'building OK'

    def run_apply(self):
        ''' Process the results of apply.
            The ouput generated by the prediction are:       
            1. prediction-results.pkl and prediction-meta.pkl 
            2. console output
            2. molecular descriptors file in TSV format [optional]
            3. results file in TSV format [optional]
        '''

        # if len(self.conveyor.getMain()) == 0:
        #     self.conveyor.setError('Unable to find main prediction')
        
        if not self.is_ensemble():
            opath = utils.predictions_repository_path()
            if os.path.isdir (opath):
                opath = os.path.join(opath,self.label)
                if not os.path.isdir (opath):
                    os.mkdir(opath)

        ###
        # 1. prediction-results.pkl and prediction-meta.pkl 
        ###

        # Save conveyor from prediction only if confidential is False
        # if not self.param.getVal('confidential') and 'ghost' not in self.format:
        if not self.is_ensemble():
            results_pkl_path = os.path.join(opath,'prediction-results.pkl')
            meta_pkl_path = os.path.join(opath,'prediction-meta.pkl')
            LOG.info(f'saving model results to: {opath}')

            # dump conveyor
            with open(results_pkl_path, 'wb') as handle:
                self.conveyor.save(handle)

            # dump metainfo
            with open(meta_pkl_path, 'wb') as handle:
                pickle.dump (self.conveyor.getMeta('endpoint'),handle)
                pickle.dump (self.conveyor.getMeta('version'),handle)
                pickle.dump (self.conveyor.getMeta('input_file'),handle)
                now = datetime.now()
                pickle.dump (now.strftime("%d/%m/%Y %H:%M:%S"),handle)
                pickle.dump (datetime.timestamp(now), handle)
                pickle.dump (self.conveyor.getMeta('modelID'),handle)
                pickle.dump (self.conveyor.getWarningMessage(), handle)
                pickle.dump (self.conveyor.getErrorMessage(), handle)

        ####
        # !  in case of error, print and return error
        ####
        if self.conveyor.getError():
            error_msg = self.conveyor.getErrorMessage()
            return False, error_msg

        ####
        # 2. console output
        ####
        #print (self.results)

        # if self.conveyor.isKey('p0'):
        #     output_predictions = open("predictions_pvalues.tsv", "w")
        #     output_predictions.write("name\tprediction\tpvalue0\tpvalue1\n")

        if not self.is_ensemble() and not 'JSON' in self.format:

            self.print_result(('obj_num','number of objects',self.conveyor.getVal('obj_num')))

            if self.conveyor.isKey('external-validation'):
                for val in self.conveyor.getVal('external-validation'):
                    self.print_result (val)   

            if self.conveyor.isKey('values'):
                nams = self.conveyor.getVal('obj_nam')
                vals = self.conveyor.getVal('values')

                pval1 = self.conveyor.getVal('p0')
                pval2 = self.conveyor.getVal('p1')
                
                for i in range (self.conveyor.getVal('obj_num')):
                   # print (self.conveyor.getVal('obj_nam')[i], '\t' , float("{0:.4f}".format(self.conveyor.getVal('values')[i])))
                   # print (f'{nams[i]}\t{vals[i]:.4f}')

                    if self.conveyor.isKey('p0'):        
                       output = f'{nams[i]}\t{vals[i]:.4f}\t{pval1[i]:.4f}\t{pval2[i]:.4f}\n'
                    #    output_predictions.write(output)
                    else:
                       output = f'{nams[i]}\t{vals[i]:.4f}'
                    print(output)
        
                # if self.conveyor.isKey('p0'):        
                #     output_predictions.close()

        ###
        # 3. molecular descriptors file in TSV format [optional]
        ###
        if 'ghost' not in self.format:
            if self.param.getVal('output_md'):
                self._output_md()

        ###
        # 4. results file in TSV format [optional]
        ### 
        if not self.is_ensemble() and 'TSV' in self.format:
            LOG.info('writting results to TSV file "output.tsv"')
            # label and smiles
            key_list = ['obj_nam']
            if self.conveyor.isKey('SMILES'):
                key_list.append('SMILES')

            # main result
            key_list += self.conveyor.getMain()

            # add all object type results
            # manifest = self.results['manifest']
            # for item in manifest:
            #     if item['dimension'] == 'objs' and item['key'] not in key_list:
            #         key_list.append(item['key'])
            key_obj = self.conveyor.objectKeys()

            for i in key_obj:
                if i not in key_list:
                    key_list.append(i)

            with open('output.tsv', 'w') as fo:
                header = ''
                for label in key_list:
                    header += label+'\t'
                fo.write(header+'\n')

                obj_num = int(self.conveyor.getVal('obj_num'))

                for i in range(obj_num):
                    line = ''
                    for key in key_list:

                        ikey = self.conveyor.getVal(key)

                        if ikey is None:
                            line += '-\t'
                            continue

                        if i >= len(ikey):
                            val = None
                        else:
                            val = ikey[i]

                        if val is None:
                            line += '-'
                        else:
                            if isinstance(val, float):
                                line += "%.4f" % val
                            
                            elif isinstance(val, list): 
                                for ival in val:
                                    if isinstance(ival, float):
                                        line += "%.4f" % ival
                                    else:
                                        line += str(ival)
                                        
                                    if ival!= val[-1]:
                                        line += '\t'
                            else:
                                line += str(val)
                        line += '\t'



                    fo.write(line+'\n')

        return True, self.conveyor



    def run_slearn(self):
        '''Process the results of slearn,
        usually a report on the space creation 
        '''
        # the ouput generated by the building are:
        # 
        # 1. results.pkl
        # 2. console output

        ####
        # 1. results.pkl
        ####

        model_path = self.param.getVal('model_path')

        results_pkl_path = os.path.join(model_path, 'space-results.pkl')
        LOG.debug(f'saving space results to: {results_pkl_path}')
        with open(results_pkl_path, 'wb') as handle:
            self.conveyor.save(handle)

        meta_pkl_path = os.path.join(model_path, 'space-meta.pkl')
        LOG.debug(f'saving space meta to: {meta_pkl_path}')
        with open(meta_pkl_path, 'wb') as handle:
            pickle.dump (self.conveyor.getMeta('modelID'), handle)
            pickle.dump (self.conveyor.getErrorMessage(), handle)
            pickle.dump (self.conveyor.getWarningMessage(), handle)
            pickle.dump (self.conveyor.getVal('space_build_info'), handle)

        ####
        # !  in case of error, print and return error
        ####
        if self.conveyor.getError():
            error_msg = self.conveyor.getErrorMessage()
            return False, error_msg

        ####
        # 2. console output
        ####
        if self.conveyor.isKey('space_build_info'):
            for val in self.conveyor.getVal('space_build_info'):
                self.print_result (val)  

        return True, self.conveyor


    def run_sapply(self):
        '''Process the results of sapply,
        usually a report on the space creation 
        '''

        # initial check
        if not self.conveyor.isKey('search_results'):
            if not self.conveyor.getError():
                self.conveyor.setError('results not found')

        results = self.conveyor.getVal('search_results')
        names   = self.conveyor.getVal('obj_nam')
        ids     = self.conveyor.getVal('obj_id')
        smiles  = self.conveyor.getVal('SMILES')
        # metric  = self.conveyor.getVal('metric')

        if results is not None and names is not None:
            if len (results) != len (names):
                if not self.conveyor.getError():
                    self.conveyor.setError('results length does not match names')
        
        # the ouput generated by the search are:
        # 
        # 1. save in a temp file for asyncronous similarity search
        # 2. console output
        # 3. results file in TSV format [optional]
        
        ####
        # 1. save in a temp file for asyncronous similarity search
        ####
        opath = tempfile.gettempdir()
        if not os.path.isdir(opath):
            return False, 'unable to save results'

        search_pkl_path = os.path.join(opath,'similars-'+self.label+'.pkl')
        LOG.info(f'saving search results to: {search_pkl_path}')

        with open(search_pkl_path, 'wb') as handle:
            self.conveyor.save(handle)

        ####
        # !  in case of error, print and return error
        ####
        if self.conveyor.getError():
            error_msg = self.conveyor.getErrorMessage()
            return False, error_msg

        ####
        # 2. console output
        ####
        if not 'JSON' in self.format:

            for i in range (len(results)):

                if smiles is None:
                    print (f'similars to {names[i]}')
                elif ids is None:
                    print (f'similars to {names[i] } [{smiles[i]}]')
                else:
                    print (f'similars to {names[i] } id:{ids[i]} [{smiles[i]}]')

                iresult = results[i]
                for j in range (len(iresult['distances'])):
                    dist = iresult['distances'][j]
                    if 'obj_name' in iresult:
                        name = iresult['obj_nam'][j]
                    else:
                        name = '-'
                    if 'SMILES' in iresult:
                        smil = iresult['SMILES'][j]
                    else:
                        smil = '-'
                    
                    if 'obj_id' in iresult:
                        idv = iresult['obj_id'][j]
                    else:
                        idv ='-'
                    
                    if 'ymatrix' in iresult:
                        act = iresult['ymatrix'][j]
                    else:
                        act = '-'

                    print (f'   {dist:.3f} : {name} id:{idv} act:{act} [{smil}]')
        
        ###
        # 3. results file in TSV format [optional]
        ### 
        if 'TSV' in self.format:
            LOG.info('writting results to TSV file "output.tsv"')

            with open('output.tsv', 'w') as fo:
                header = 'source_name'
                if self.conveyor.isKey('SMILES'):
                    header +='\tsource SMILES'
                header+='\tsimilarity\tname\tSMILES'
                fo.write(header+'\n')

                for i in range (len(results)):                    
                    iresult = results[i]
                    for j in range (len(iresult['distances'])):

                        if self.conveyor.isKey('SMILES'):
                            line = f'{names[i]}\t[{smiles[i]}]\t'
                        else:
                            line = f'{names[i]}\t'
  
                        dist = iresult['distances'][j]
                        
                        if 'obj_name' in iresult:
                            name = iresult['obj_nam'][j]
                        else:
                            name = '-'
                        if 'SMILES' in iresult:
                            smil = iresult['SMILES'][j]
                        else:
                            smil = '-'
                        
                        if 'obj_id' in iresult:
                            idv = iresult['obj_id'][j]
                        else:
                            idv ='-'
                        
                        if 'ymatrix' in iresult:
                            act = iresult['ymatrix'][j]
                        else:
                            act = '-'

                        line += f'{dist:.3f}\t{name}\t{idv}\t[{smil}]\t{act}'
                        fo.write(line+'\n')

        return True, self.conveyor


    def run(self):
        '''Formats the results produced by "learn", "apply", etc.'''

        origin = self.conveyor.getOrigin()

        LOG.debug (f'Starting to produce output from run of type "{origin}" ')

        if   origin == 'learn':
            success, results = self.run_learn()
        elif origin == 'apply':
            success, results = self.run_apply()
            # we removed this option, because it stores the search resuls in a temp file which has no use
            # if self.param.getVal('output_similar'):
            #     success, results = self.run_sapply()
        elif origin == 'slearn':
            success, results = self.run_slearn()
        elif origin == 'sapply':
            success, results = self.run_sapply()
        else:
            return False, 'processing output from a run of unknown type'

        return success, results

    def aggregate (self, input_source):
        ''' input source is a list of conveyors obtained by different models'''

        opath = utils.profiles_repository_path()
        if os.path.isdir (opath):
            opath = os.path.join(opath,self.label)
            if not os.path.isdir (opath):
                os.mkdir(opath)

        # create output files 
        results_pkl_path = os.path.join(opath,'profile-results.pkl')
        meta_pkl_path = os.path.join(opath,'profile-meta.pkl')
        LOG.info(f'saving profiling results to: {opath}')

        nmodels = len(input_source)

        # dump results
        with open(results_pkl_path, 'wb') as handle:
            pickle.dump (nmodels, handle)
            for iconveyor in input_source: 
                iconveyor.save(handle)

        # dump metainfo
        with open(meta_pkl_path, 'wb') as handle:
            pickle.dump (nmodels, handle)
            for iconveyor in input_source: 
                now = datetime.now()
                pickle.dump (iconveyor.getMeta('endpoint'),handle)
                pickle.dump (iconveyor.getMeta('version'),handle)
                pickle.dump (iconveyor.getMeta('input_file'),handle)
                pickle.dump (now.strftime("%d/%m/%Y %H:%M:%S"),handle)
                pickle.dump (datetime.timestamp(now), handle)
                pickle.dump (iconveyor.getMeta('modelID'),handle)
                # pickle.dump (iconveyor.getWarningMessage(), handle)
                # pickle.dump (iconveyor.getErrorMessage(), handle)

            # print (iconveyor.getJSON())

        ####
        # 2. console output
        ####
        
        obj_num = input_source[0].getVal('obj_num')
        self.print_result(('obj_num','number of objects',obj_num))
        
        names  = []
        values = []
        pval0  = []
        pval1  = []
        first = True

        for iconveyor in input_source: 
            if iconveyor.isKey('values'):
                if first:
                    names  = iconveyor.getVal('obj_nam')
                    values = np.array(iconveyor.getVal('values'), dtype=np.float64)
                    if iconveyor.isKey('p0'):
                        pval0 = np.array(iconveyor.getVal('p0'), dtype=np.float64)
                        pval1 = np.array(iconveyor.getVal('p1'), dtype=np.float64)
                    else:
                        pval0 = np.zeros((obj_num), dtype=np.float64)
                        pval1 = np.zeros((obj_num), dtype=np.float64)
                    first  = False
                else:
                    values = np.c_[values, iconveyor.getVal('values')]
                    if iconveyor.isKey('p0'):
                        pval0 = np.c_[pval0, iconveyor.getVal('p0')]
                        pval1 = np.c_[pval1, iconveyor.getVal('p1')]
                    else:
                        pval0 = np.c_[pval0, np.zeros((obj_num), dtype=np.float64)]
                        pval1 = np.c_[pval1, np.zeros((obj_num), dtype=np.float64)]

        #header
        output = 'name       '
        for j in range (nmodels):
            output += f'\t{input_source[j].getMeta("endpoint")}v{input_source[j].getMeta("version")}'
            if input_source[j].isKey('p0'):
                output += '\tp0\tp1'
        print (output)

        #table
        for i in range(obj_num):
            output = f'{names[i]}'
            for j in range (nmodels):
                if input_source[j].isKey('p0'):
                    output += f'\t{values[i][j]:.4f}\t{pval0[i][j]:.4f}\t{pval1[i][j]:.4f}'
                else:
                    output += f'\t{values[i][j]:.4f}'
            print (output)

        # return True, 'OK'
        return True, output